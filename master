#!/bin/bash
DOCKER_VERSION=5:18.09.8~3-0~debian-stretch

####################################################################################################
# for Debian k8s master setup
####################################################################################################

##########################################################################################
## Get Docker Engine - Community for Debian
## reference url:
## https://docs.docker.com/install/linux/docker-ce/debian/
##########################################################################################

##################################################
### SET UP THE REPOSITORY
##################################################

# 1. Update the apt package index:
cat << EOF
##command##
## sudo apt-get update -y
## 
EOF

#sudo apt-get update
sudo apt-get update -y

# 2. Install packages to allow apt to use a repository over HTTPS:
cat << EOF
##command##
## sudo apt-get install -y \
        apt-transport-https \
        ca-certificates \
        curl \
        gnupg2 \
        software-properties-common
## 
EOF

#sudo apt-get install \
sudo apt-get install -y \
     apt-transport-https \
     ca-certificates \
     curl \
     gnupg2 \
     software-properties-common
    
# 3. Add Docker’s official GPG key:
cat << EOF
##command##
## curl -fsSL https://download.docker.com/linux/debian/gpg | sudo apt-key add -
## 
EOF

curl -fsSL https://download.docker.com/linux/debian/gpg | sudo apt-key add -

# 4. Use the following command to set up the stable repository. 
#    To add the nightly or test repository, add the word nightly or test (or both) 
#    after the word stable in the commands below. Learn about nightly and test channels.
cat << EOF
##command##
## sudo add-apt-repository \
        "deb [arch=amd64] https://download.docker.com/linux/debian \
        $(lsb_release -cs) \
        stable"
EOF

sudo add-apt-repository \
     "deb [arch=amd64] https://download.docker.com/linux/debian \
     $(lsb_release -cs) \
     stable"

##################################################
### INSTALL DOCKER ENGINE - COMMUNITY
##################################################

# 1. Update the apt package index.
cat << EOF
##command##
## sudo apt-get update -y
## 
EOF

#sudo apt-get update
sudo apt-get update -y

# 2. Install the latest version of Docker Engine - Community and containerd, 
#    or go to the next step to install a specific version:
#cat << EOF
##command##
## sudo apt-get install -y docker-ce docker-ce-cli containerd.io
#EOF

#sudo apt-get install docker-ce docker-ce-cli containerd.io
#sudo apt-get install -y docker-ce docker-ce-cli containerd.io

# 3. To install a specific version of Docker Engine - Community, 
# list the available versions in the repo, then select and install:

# List the versions available in your repo:
apt-cache madison docker-ce

echo "########## SPECIFIC DOCKER VERSION ###########"
echo "Specific Docker Version=$DOCKER_VERSION"
cat << EOF
##command##
## 
## sudo apt-get install -y docker-ce=$DOCKER_VERSION docker-ce-cli=$DOCKER_VERSION containerd.io
## 
EOF

sudo apt-get install -y docker-ce=$DOCKER_VERSION docker-ce-cli=$DOCKER_VERSION containerd.io

##########################################################################################
## k8s setup with kubeadm
## reference url:
## https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/
##########################################################################################

##################################################
### Installing kubeadm, kubelet and kubectl
##################################################

cat << EOF
##command##
## sudo apt-get update -y && sudo apt-get install -y apt-transport-https curl
##
## curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
##
## sudo tee /etc/apt/sources.list.d/kubernetes.list <<E0F
## deb https://apt.kubernetes.io/ kubernetes-xenial main
## E0F
##
## sudo apt-get update -y
## sudo apt-get install -y kubelet kubeadm kubectl
## sudo apt-mark hold kubelet kubeadm kubectl
## 
EOF

#apt-get update && apt-get install -y apt-transport-https curl
sudo apt-get update -y && sudo apt-get install -y apt-transport-https curl

curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -

# change command `cat` to `tee` for sudo
#cat <<EOF >/etc/apt/sources.list.d/kubernetes.list
#deb https://apt.kubernetes.io/ kubernetes-xenial main
#EOF

sudo tee /etc/apt/sources.list.d/kubernetes.list <<EOF
deb https://apt.kubernetes.io/ kubernetes-xenial main
EOF

#apt-get update
sudo apt-get update -y

#apt-get install -y kubelet kubeadm kubectl
sudo apt-get install -y kubelet kubeadm kubectl

#apt-mark hold kubelet kubeadm kubectl
sudo apt-mark hold kubelet kubeadm kubectl

##################################################
### Configure cgroup driver used by kubelet 
### on control-plane node
##################################################

# When using Docker, kubeadm will automatically detect the cgroup driver for 
# the kubelet and set it in the /var/lib/kubelet/kubeadm-flags.env file during runtime.
# 
# If you are using a different CRI, you have to modify the 
# file /etc/default/kubelet with your cgroup-driver value, like so:

#KUBELET_EXTRA_ARGS=--cgroup-driver=<value>

# This file will be used by kubeadm init and kubeadm join to source extra 
# user defined arguments for the kubelet.
# 
# Please mind, that you only have to do that if the cgroup driver of your CRI 
# is not cgroupfs, because that is the default value in the kubelet already.
# 
# Restarting the kubelet is required:

#systemctl daemon-reload
#systemctl restart kubelet

# The automatic detection of cgroup driver for other container runtimes like CRI-O and containerd is work in progress

##################################################
### Creating a single control-plane cluster 
### with kubeadm 
##################################################

#kubeadm init <args>
#
# Case. Use calico
#kubeadm init --pod-network-cidr=192.168.0.0/16
#
# Case. Use flannel
#kubeadm init --pod-network-cidr=10.244.0.0/16

cat << EOF
##command##
## sudo kubeadm init --pod-network-cidr=10.244.0.0/16
##
## mkdir -p $HOME/.kube
## sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
## sudo chown $(id -u):$(id -g) $HOME/.kube/config
## 
EOF

sudo kubeadm init --pod-network-cidr=10.244.0.0/16

mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

# For flannel to work correctly, you must pass --pod-network-cidr=10.244.0.0/16 to kubeadm init.
# Set /proc/sys/net/bridge/bridge-nf-call-iptables to 1 by running 
# sysctl net.bridge.bridge-nf-call-iptables=1 to pass bridged IPv4 traffic to iptables’ chains. 
# This is a requirement for some CNI plugins to work, for more information please see here.

sudo sysctl net.bridge.bridge-nf-call-iptables=1

# Make sure that your firewall rules allow UDP ports 8285 and 8472 traffic for all 
# hosts participating in the overlay network. see here .

# Note that flannel works on amd64, arm, arm64, ppc64le and s390x under Linux. 
# Windows (amd64) is claimed as supported in v0.11.0 but the usage is undocumented.

kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/62e44c867a2846fefb68bd5f178daf4da3095ccb/Documentation/kube-flannel.yml

# For more information about flannel, see the CoreOS flannel repository on GitHub .


# Once a pod network has been installed, you can confirm that it is working by checking that the 
# CoreDNS pod is Running in the output of kubectl get pods --all-namespaces. 
# And once the CoreDNS pod is up and running, you can continue by joining your nodes.

# If your network is not working or CoreDNS is not in the Running state, checkout our troubleshooting docs.

sleep 10
kubectl get pods --all-namespaces

##################################################
### Control plane node isolation
##################################################

# By default, your cluster will not schedule pods on the control-plane node for security reasons. 
# If you want to be able to schedule pods on the control-plane node, e.g. for a single-machine 
# Kubernetes cluster for development, run:

#kubectl taint nodes --all node-role.kubernetes.io/master-

# With output looking something like:

# node "test-01" untainted
# taint "node-role.kubernetes.io/master:" not found
# taint "node-role.kubernetes.io/master:" not found

# This will remove the node-role.kubernetes.io/master taint from any nodes that have it, 
# including the control-plane node, meaning that the scheduler will then be able to schedule pods everywhere.





##########################################################################################
## wait for Joining worker node 
##########################################################################################

cat << EOF
###########################################################################
Please setup worker nodes.
The master node keep this state for 300 seconds.

  $ docker run --rm -d --name token-nginx
               --publish 9999:80
	       --mount type=bind,source=\$PWD,target=/usr/share/nginx/html/
	       nginx

Then run the following command...

  $ docker stop token-nginx

EOF

sudo kubeadm token create --print-join-command > index.html
sudo sed -i '1s/^/sudo /' index.html
sudo docker run --rm -d --name token-nginx \
                --publish 9999:80 \
                --mount type=bind,source=$PWD,target=/usr/share/nginx/html/ \
                nginx

for ((i = 1; i <= 10; i++))
do
  bar=$bar'##'
  percent=$((i * 10))
  echo -ne "$bar ($percent%)\r"
  sleep 30
done
echo -ne '\n'

sudo docker stop token-nginx
sudo docker image rm nginx


echo "finished!"

